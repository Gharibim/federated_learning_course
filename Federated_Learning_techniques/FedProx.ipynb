{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import syft as sy\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import importlib\n",
    "importlib.import_module('FLDataset')\n",
    "from FLDataset import load_dataset, getActualImgs\n",
    "from utils import averageModels, averageGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.images = 60000\n",
    "        self.clients = 50\n",
    "        self.rounds = 5\n",
    "        self.epochs = 5\n",
    "        self.local_batches = 1\n",
    "        self.lr = 0.01\n",
    "        self.C = 0.9\n",
    "        self.drop_rate = 0.1\n",
    "        self.mu = 0.1\n",
    "        self.torch_seed = 0\n",
    "        self.log_interval = 10\n",
    "        self.iid = 'iid'\n",
    "        self.split_size = int(self.images / self.clients)\n",
    "        self.samples = self.split_size / self.images \n",
    "        self.use_cuda = False\n",
    "        self.save_model = False\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = args.use_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-actress",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(torch)\n",
    "clients = []\n",
    "\n",
    "for i in range(args.clients):\n",
    "    clients.append({'hook': sy.VirtualWorker(hook, id=\"client{}\".format(i+1))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "globa_train, global_test, train_group, test_group = load_dataset(args.clients, args.iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inx, client in enumerate(clients):\n",
    "    client['trainset'] = getActualImgs(globa_train, list(train_group[inx]), args.local_batches)\n",
    "    client['testset'] = getActualImgs(global_test, list(test_group[inx]), args.local_batches)\n",
    "    client['samples'] = len(client['trainset']) / args.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-dispute",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "global_test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "global_test_loader = DataLoader(global_test_dataset, batch_size=args.local_batches, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-collector",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClientUpdate(args, device, client, global_model, rclients=False):\n",
    "    client['model'].train()\n",
    "    Epochs = args.epochs + 1\n",
    "    if rclients:\n",
    "        Epochs = np.random.randint(low=1, high=Epochs)\n",
    "        Epochs = 2\n",
    "\n",
    "    for epoch in range(1, Epochs):\n",
    "        for batch_idx, (data, target) in enumerate(client['trainset']):\n",
    "            data = data.send(client['hook'])\n",
    "            target = target.send(client['hook'])\n",
    "            client['model'].send(data.location)\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            client['optim'].zero_grad()\n",
    "            output = client['model'](data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            client['optim'].step(global_model.send(client['hook']))\n",
    "            client['model'].get() \n",
    "            global_model.get()\n",
    "\n",
    "            if batch_idx % args.log_interval == 0:\n",
    "                loss = loss.get() \n",
    "                print('Model {} Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    client['hook'].id,\n",
    "                    epoch, batch_idx * args.local_batches, len(client['trainset']) * args.local_batches, \n",
    "                    100. * batch_idx / len(client['trainset']), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader, name):\n",
    "    model.eval()   \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss for {} model: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        name, test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedProxOptim(optim.Optimizer):\n",
    "    def __init__(self, params, lr=args.lr, mu=args.mu):\n",
    "        defaults = dict(lr=lr, mu=mu)\n",
    "        super(FedProxOptim, self).__init__(params, defaults)\n",
    "    \n",
    "    def step(self, global_model=None, closure = None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "        for group in self.param_groups:\n",
    "            lr, mu = group['lr'], group['mu']\n",
    "            for p in zip(group['params'], list(global_model.parameters())):\n",
    "                if p[0].grad is None:\n",
    "                    continue\n",
    "                d_p = p[0].grad.data # local model grads\n",
    "                p[0].data.sub_(group['lr'], (d_p + mu * (p[0].data.clone() - p[1].data.clone())))\n",
    "                \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args.torch_seed)\n",
    "global_model = Net().to(device)\n",
    "\n",
    "for client in clients:\n",
    "    torch.manual_seed(args.torch_seed)\n",
    "    client['model'] = Net().to(device)\n",
    "    client['optim'] = FedProxOptim(client['model'].parameters(), lr=args.lr, mu=args.mu)\n",
    "\n",
    "for fed_round in range(args.rounds):\n",
    "    \n",
    "    m = int(max(args.C * args.clients, 1))\n",
    "    \n",
    "    # Selected devices\n",
    "    np.random.seed(fed_round)\n",
    "    selected_clients_inds = np.random.choice(range(len(clients)), m, replace=False)\n",
    "    selected_clients = [clients[i] for i in selected_clients_inds]\n",
    "    \n",
    "    # Active devices\n",
    "    active_clients_inds = np.random.choice(selected_clients_inds, int((1-args.drop_rate) * m), replace=False)\n",
    "    active_clients = [clients[i] for i in active_clients_inds]\n",
    "    \n",
    "    # The rest of the active devices (selected but dropped)\n",
    "    rest_clients_inds = np.setdiff1d(selected_clients_inds, active_clients_inds)\n",
    "    rest_clients = [clients[i] for i in rest_clients_inds]\n",
    "    \n",
    "\n",
    "    # Training the active devices\n",
    "    for client in active_clients:\n",
    "        ClientUpdate(args, device, client, global_model)\n",
    "    \n",
    "\n",
    "    # Training the rest with less number of epochs\n",
    "    for client in rest_clients:\n",
    "        ClientUpdate(args, device, client, global_model, True)\n",
    "\n",
    "\n",
    "    global_model = averageModels(global_model, selected_clients)\n",
    "    \n",
    "    test(args, global_model, device, global_test_loader, 'Global')\n",
    "    \n",
    "    for client in clients:\n",
    "        client['model'].load_state_dict(global_model.state_dict())\n",
    "\n",
    "if (args.save_model):\n",
    "    torch.save(global_model.state_dict(), \"FedProx.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-spanish",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
