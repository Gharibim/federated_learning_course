{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-progressive",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import syft as sy\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "from FLDataset import load_dataset, getActualImgs\n",
    "from utils import averageModels, averageGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.images = 60000\n",
    "        self.clients = 10\n",
    "        self.epochs = 5\n",
    "        self.local_batches = self.images // self.clients\n",
    "        self.lr = 0.01\n",
    "        self.torch_seed = 0\n",
    "        self.log_interval = 10\n",
    "        self.iid = 'iid'\n",
    "        self.split_size = int(self.images / self.clients)\n",
    "        self.samples = self.split_size / self.images \n",
    "        self.use_cuda = False\n",
    "        self.save_model = False\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = args.use_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(torch)\n",
    "clients = []\n",
    "\n",
    "for i in range(args.clients):\n",
    "    clients.append({'hook': sy.VirtualWorker(hook, id=\"client{}\".format(i+1))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The error for downloading MNIST Dataset as fixed, you do not need to include the following 4 lines\n",
    "# ====================================================================\n",
    "\n",
    "# from six.moves import urllib\n",
    "# opener = urllib.request.build_opener()\n",
    "# opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "# urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_train, global_test, train_group, test_group = load_dataset(args.clients, args.iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inx, client in enumerate(clients):\n",
    "    client['trainset'] = getActualImgs(global_train, list(train_group[inx]), args.local_batches)\n",
    "    client['testset'] = getActualImgs(global_test, list(test_group[inx]), args.local_batches)\n",
    "    client['samples'] = len(client['trainset']) / args.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_test_loader = DataLoader(global_test, batch_size=args.local_batches, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-shopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-chapel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, clientss, device, epoch):\n",
    "    client['model'].train()\n",
    "    for batch_idx, (data, target) in enumerate(client['trainset']):\n",
    "        data = data.send(client['hook'])\n",
    "        target = target.send(client['hook'])\n",
    "        client['model'].send(data.location)\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        client['optim'].zero_grad()\n",
    "        output = client['model'](data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "#         client['optim'].step()\n",
    "        client['model'].get() \n",
    "\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            loss = loss.get() \n",
    "            print('Model {} Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                client['hook'].id,\n",
    "                epoch, batch_idx * args.local_batches, len(client['trainset']) * args.local_batches, \n",
    "                100. * batch_idx / len(client['trainset']), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader, name):\n",
    "    model.eval()   \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss for {} model: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        name, test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedSGDOptim(optim.Optimizer):\n",
    "    def __init__(self, params, lr=args.lr):\n",
    "        defaults = dict(lr=lr)\n",
    "        super(FedSGDOptim, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, grad_model=None, closure = None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "        for group in self.param_groups:\n",
    "            lr = group['lr']\n",
    "            for p in zip(group['params'], list(grad_model.parameters())): # (p[0], p[1])\n",
    "                if p[0].grad is None:\n",
    "                    continue\n",
    "#                 d_p = p[0].grad.data # local model grads\n",
    "                p[0].data.add_(-group['lr'], p[1].grad.data.clone())  \n",
    "          \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args.torch_seed)\n",
    "global_model = Net().to(device)\n",
    "optimizer = FedSGDOptim(global_model.parameters(), lr=args.lr)\n",
    "grad_model = Net().to(device)\n",
    "\n",
    "for client in clients:\n",
    "    torch.manual_seed(args.torch_seed)\n",
    "    client['model'] = Net().to(device)\n",
    "    client['optim'] = optim.SGD(client['model'].parameters(), lr=args.lr)\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    \n",
    "    for client in clients:\n",
    "        train(args, client, device, epoch)\n",
    "    \n",
    "    grad_model = averageGradients(global_model, clients)\n",
    "    \n",
    "#     # Testing \n",
    "#     for client in clients:\n",
    "#         test(args, client['model'], device, client['testset'], client['hook'].id)\n",
    "\n",
    "    test(args, global_model, device, global_test_loader, 'Global')\n",
    "    optimizer.step(grad_model)\n",
    "    test(args, global_model, device, global_test_loader, 'Global')\n",
    "    \n",
    "    # Share global model\n",
    "    for client in clients:\n",
    "        client['model'].load_state_dict(global_model.state_dict())\n",
    "\n",
    "if (args.save_model):\n",
    "    torch.save(global_model.state_dict(), \"FedSGD.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(global_model.parameters())[0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-passage",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
