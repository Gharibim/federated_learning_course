{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "duet1 = sy.join_duet(\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\")\n",
    "sy.logger.add(sink=\"./syft_ds.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-police",
   "metadata": {},
   "outputs": [],
   "source": [
    "duet1.torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "duet2 = sy.join_duet(\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-miracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets define a few settings which are from the original MNIST example command-line args\n",
    "args = {\n",
    "    \"images\": 60000,\n",
    "    \"clients\": 2,\n",
    "    \"rounds\": 4,\n",
    "    \"batch_size\": 64,\n",
    "    \"test_batch_size\": 1000,\n",
    "    \"epochs\": 4,\n",
    "    \"lr\": 1.0,\n",
    "    \"gamma\": 0.7,\n",
    "    \"no_cuda\": False,\n",
    "    \"dry_run\": False,\n",
    "    \"torch_seed\": 0, # the meaning of life\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyNet(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(SyNet, self).__init__(torch_ref=torch_ref)\n",
    "        self.conv1 = self.torch_ref.nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = self.torch_ref.nn.Conv2d(32, 64, 3, 1) \n",
    "        self.dropout1 = self.torch_ref.nn.Dropout2d(0.25)\n",
    "        self.dropout2 = self.torch_ref.nn.Dropout2d(0.5)\n",
    "        self.fc1 = self.torch_ref.nn.Linear(9216, 128)\n",
    "        self.fc2 = self.torch_ref.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        x = self.torch_ref.nn.functional.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.torch_ref.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = self.torch_ref.nn.functional.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-basis",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = []\n",
    "\n",
    "for i in range(args['clients']):\n",
    "    clients.append({'duet': eval(\"duet{}\".format(i+1))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args['torch_seed'])\n",
    "local_model = SyNet(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need some transforms for the MNIST data set\n",
    "local_transform_1 = torchvision.transforms.ToTensor()  # this converts PIL images to Tensors\n",
    "local_transform_2 = torchvision.transforms.Normalize(0.1307, 0.3081)  # this normalizes the dataset\n",
    "\n",
    "# compose our transforms\n",
    "local_transforms = torchvision.transforms.Compose([local_transform_1, local_transform_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will configure the test set here locally since we want to know if our Data Owner's\n",
    "# private training dataset will help us reach new SOTA results for our benchmark test set\n",
    "test_kwargs = {\n",
    "    \"batch_size\": args[\"test_batch_size\"],\n",
    "}\n",
    "\n",
    "test_data = torchvision.datasets.MNIST('./data', train=False, download=True, transform=local_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,**test_kwargs)\n",
    "test_data_length = len(test_loader.dataset)\n",
    "print(test_data_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-cowboy",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, client in enumerate(clients):\n",
    "    client['remote_torch'] = client['duet'].torch\n",
    "    torch.manual_seed(ind)\n",
    "    client['model'] = SyNet(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets ask to see if our Data Owner has CUDA\n",
    "has_cuda = False\n",
    "print(has_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-congo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(client, epoch, args):\n",
    "    # + 0.5 lets us math.ceil without the import\n",
    "    train_batches = round((client['train_data_length'] / args[\"batch_size\"]) + 0.5)\n",
    "    print(f\"> Running train in {train_batches} batches\")\n",
    "    if client['remote_model'].is_local:\n",
    "        print(\"Training requires remote model\")\n",
    "        return\n",
    "\n",
    "    client['remote_model'].train()\n",
    "\n",
    "    for batch_idx, data in enumerate(client['train_loader_ptr']):\n",
    "        data_ptr, target_ptr = data[0], data[1]\n",
    "        client['optim'].zero_grad()\n",
    "        output = client['remote_model'](data_ptr)\n",
    "        loss = client['remote_torch'].nn.functional.nll_loss(output, target_ptr)\n",
    "        loss.backward()\n",
    "        client['optim'].step()\n",
    "        loss_item = loss.item()\n",
    "        train_loss = client['duet'].python.Float(0)  # create a remote Float we can use for summation\n",
    "        train_loss += loss_item\n",
    "        if batch_idx % args[\"log_interval\"] == 0:\n",
    "            local_loss = None\n",
    "            local_loss = loss_item.get(\n",
    "                name=\"loss\",\n",
    "                reason=\"To evaluate training progress\",\n",
    "                request_block=True,\n",
    "                timeout_secs=5\n",
    "            )\n",
    "            if local_loss is not None:\n",
    "                print(\"Train Epoch: {} {} {:.4}\".format(epoch, batch_idx, local_loss))\n",
    "            else:\n",
    "                print(\"Train Epoch: {} {} ?\".format(epoch, batch_idx))\n",
    "            if args[\"dry_run\"]:\n",
    "                break\n",
    "        if batch_idx >= train_batches - 1:\n",
    "            print(\"batch_idx >= train_batches, breaking\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_local(model, test_loader, test_data_length):\n",
    "    current_model = None\n",
    "    # download remote model\n",
    "    if not model.is_local:\n",
    "        current_model = model.get(\n",
    "            request_block=True,\n",
    "            name=\"model_download\",\n",
    "            reason=\"test evaluation\",\n",
    "            timeout_secs=5\n",
    "        )\n",
    "    else:\n",
    "        current_model = model\n",
    "    # + 0.5 lets us math.ceil without the import\n",
    "    test_batches = round((test_data_length / args[\"test_batch_size\"]) + 0.5)\n",
    "    print(f\"> Running test_local in {test_batches} batches\")\n",
    "    current_model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            output = current_model(data)\n",
    "            iter_loss = torch.nn.functional.nll_loss(output, target, reduction=\"sum\").item()\n",
    "            test_loss = test_loss + iter_loss\n",
    "            pred = output.argmax(dim=1)\n",
    "            total = pred.eq(target).sum().item()\n",
    "            correct += total\n",
    "            if args[\"dry_run\"]:\n",
    "                break\n",
    "                \n",
    "            if batch_idx >= test_batches - 1:\n",
    "                print(\"batch_idx >= test_batches, breaking\")\n",
    "                break\n",
    "\n",
    "    accuracy = correct / test_data_length\n",
    "    print(f\"Test Set Accuracy: {100 * accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def averageModels(global_model, clients):\n",
    "    client_models = [clients[i]['model'] for i in range(len(clients))]\n",
    "    samples = [clients[i]['samples'] for i in range(len(clients))]\n",
    "    global_dict = global_model.state_dict()\n",
    "    \n",
    "    for k in global_dict.keys():\n",
    "        global_dict[k] = torch.stack([client_models[i].state_dict()[k].float() * samples[i] for i in range(len(client_models))], 0).sum(0)\n",
    "            \n",
    "    global_model.load_state_dict(global_dict)\n",
    "    return global_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The DO has kindly let us initialise a DataLoader for their training set\n",
    "train_kwargs = {\n",
    "    \"batch_size\": args[\"batch_size\"],\n",
    "}\n",
    "\n",
    "for ind, client in enumerate(clients):\n",
    "    client['remote_torchvision'] = client['duet'].torchvision\n",
    "    \n",
    "    transform_1 = client['remote_torchvision'].transforms.ToTensor()\n",
    "    transform_2 = client['remote_torchvision'].transforms.Normalize(0.1307, 0.3081)\n",
    "    \n",
    "    client['remote_list'] = client['duet'].python.List()  # create a remote list to add the transforms to\n",
    "    client['remote_list'].append(transform_1)\n",
    "    client['remote_list'].append(transform_2)\n",
    "    \n",
    "    client['transforms'] = client['remote_torchvision'].transforms.Compose(client['remote_list'])\n",
    "    client['train_data_ptr'] = client['remote_torchvision'].datasets.MNIST('./data', train=True, download=True, transform=client['transforms'])\n",
    "    client['train_loader_ptr'] = client['remote_torch'].utils.data.DataLoader(client['train_data_ptr'], **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-advisory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normally we would not necessarily know the length of a remote dataset so lets ask for it\n",
    "# so we can pass that to our training loop and know when to stop\n",
    "def get_train_length(train_data_ptr):\n",
    "    train_length_ptr = train_data_ptr.__len__()\n",
    "    train_data_length = train_length_ptr.get(\n",
    "        request_block=True,\n",
    "        name=\"train_size\",\n",
    "        reason=\"To write the training loop\",\n",
    "        timeout_secs=5,\n",
    "    )\n",
    "    return train_data_length\n",
    "\n",
    "\n",
    "for client in clients:\n",
    "    client['train_data_length'] = get_train_length(client['train_data_ptr'])\n",
    "    client['samples'] = client['train_data_length'] / args['images']\n",
    "    print(f\"Training Dataset size is: {client['train_data_length']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-senior",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "args[\"dry_run\"] = True  # comment to do a full train\n",
    "print(\"Starting Training\")\n",
    "\n",
    "for fed_round in range(args['rounds']):\n",
    "    for i, client in enumerate(clients):\n",
    "        \n",
    "        client['remote_model'] = client['model'].send(client['duet']).cpu()\n",
    "        client['optim'] = client['remote_torch'].optim.Adadelta(client['remote_model'].parameters(), lr=args['lr'])\n",
    "        client['sched'] = client['remote_torch'].optim.lr_scheduler.StepLR(client['optim'], step_size=1, gamma=args['gamma'])\n",
    "        \n",
    "        # train the clients\n",
    "        for epoch in range(1, args[\"epochs\"] + 1):\n",
    "            epoch_start = time.time()\n",
    "            print(f\"Epoch: {epoch}\")\n",
    "            # remote training on model with remote_torch\n",
    "            train(client, epoch, args)\n",
    "            client['sched'].step()\n",
    "            epoch_end = time.time()\n",
    "            print(f\"Epoch time: {int(epoch_end - epoch_start)} seconds\")\n",
    "            break\n",
    "        \n",
    "        # get the client model back for averaging\n",
    "        client['model'] = client['remote_model'].get(\n",
    "            request_block=True,\n",
    "            name=\"model_download\",\n",
    "            reason=\"test evaluation\",\n",
    "            timeout_secs=5\n",
    "        )\n",
    "\n",
    "    # Average all the clients\n",
    "    local_model = averageModels(local_model, clients)\n",
    "    \n",
    "    # local testing on model with local torch\n",
    "    test_local(local_model, test_loader, test_data_length)\n",
    "    \n",
    "    # Share the global model with the clients\n",
    "    for client in clients:\n",
    "        client['model'].load_state_dict(copy.deepcopy(local_model.state_dict()))\n",
    "    \n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-jersey",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-salon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
